{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8AEyUKcGq8G"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur3_lnYw-Sds"
      },
      "outputs": [],
      "source": [
        "import torch, os, json, random, numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DATA_DIR = '/kaggle/input/chest-xray-pneumonia/chest_xray'\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 224\n",
        "\n",
        "\n",
        "class To3Channel:\n",
        "    def __call__(self, img):\n",
        "        if img.mode != 'RGB':\n",
        "            return img.convert('RGB')\n",
        "        return img\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    To3Channel(),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.85, 1.0)),\n",
        "    transforms.RandomRotation(7),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "val_tfms = transforms.Compose([\n",
        "    To3Channel(),\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(os.path.join(DATA_DIR, 'val'),   transform=val_tfms)\n",
        "test_ds  = datasets.ImageFolder(os.path.join(DATA_DIR, 'test'),  transform=val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "idx_to_class = {v:k for k,v in train_ds.class_to_idx.items()}\n",
        "with open('labels.json','w') as f:\n",
        "    json.dump(idx_to_class, f)\n",
        "print(idx_to_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAZOKJFXJSov"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "857yE8H3A7Lx"
      },
      "outputs": [],
      "source": [
        "import timm, math, time\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "model = timm.create_model('resnet50', pretrained=True, num_classes=len(train_ds.classes))\n",
        "model = model.to(device)\n",
        "\n",
        "# Class imbalance handling\n",
        "# class_counts = torch.tensor([len([1 for p,_ in train_ds.samples if train_ds.classes[p.split(os.sep)[-2]]==c]) for c in train_ds.classes])\n",
        "# Fallback: compute by directory sizes\n",
        "class_counts = torch.tensor([len(os.listdir(os.path.join(DATA_DIR, 'train', c))) for c in train_ds.classes])\n",
        "class_weights = (class_counts.sum() / class_counts).float()\n",
        "class_weights = class_weights / class_weights.sum() * len(class_weights)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
        "\n",
        "EPOCHS = 10\n",
        "best_val_auc = -1.0\n",
        "patience, bad = 3, 0\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    y_true_tr, y_pred_tr = [], []\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            train_losses.append(loss.item())\n",
        "            y_true_tr.extend(labels.detach().cpu().numpy())\n",
        "            y_pred_tr.extend(torch.softmax(logits,1).detach().cpu().numpy())\n",
        "\n",
        "    scheduler.step()\n",
        "    train_acc = accuracy_score(y_true_tr, np.argmax(y_pred_tr,1))\n",
        "    try:\n",
        "        train_auc = roc_auc_score(y_true_tr, np.array(y_pred_tr)[:,1]) if len(train_ds.classes)==2 else float('nan')\n",
        "    except Exception:\n",
        "        train_auc = float('nan')\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            val_losses.append(loss.item())\n",
        "            y_true.extend(labels.detach().cpu().numpy())\n",
        "            y_pred.extend(torch.softmax(logits,1).detach().cpu().numpy())\n",
        "\n",
        "    val_acc = accuracy_score(y_true, np.argmax(y_pred,1))\n",
        "    try:\n",
        "        val_auc = roc_auc_score(y_true, np.array(y_pred)[:,1]) if len(train_ds.classes)==2 else float('nan')\n",
        "    except Exception:\n",
        "        val_auc = float('nan')\n",
        "\n",
        "    print(f\"Epoch {epoch}: train_loss={np.mean(train_losses):.4f} acc={train_acc:.3f} auc={train_auc:.3f} | val_loss={np.mean(val_losses):.4f} acc={val_acc:.3f} auc={val_auc:.3f}\")\n",
        "\n",
        "\n",
        "    score = val_auc if not math.isnan(val_auc) else val_acc\n",
        "    if score > best_val_auc:\n",
        "        best_val_auc = score\n",
        "        bad = 0\n",
        "        torch.save(model.state_dict(), 'xray_resnet50.pth')\n",
        "        print('‚úî Saved best model')\n",
        "    else:\n",
        "        bad += 1\n",
        "        if bad >= patience:\n",
        "            print('‚èπ Early stopping')\n",
        "            break\n",
        "\n",
        "print('Best validation metric:', best_val_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLEUHhJp_Vy3"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.load_state_dict(torch.load('xray_resnet50.pth', map_location=device))\n",
        "model.eval()\n",
        "\n",
        "all_true, all_prob = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        logits = model(imgs)\n",
        "        probs = torch.softmax(logits,1).cpu().numpy()\n",
        "        all_prob.extend(probs)\n",
        "        all_true.extend(labels.numpy())\n",
        "\n",
        "pred = np.argmax(np.array(all_prob),1)\n",
        "print(classification_report(all_true, pred, target_names=train_ds.classes))\n",
        "\n",
        "cm = confusion_matrix(all_true, pred)\n",
        "plt.figure()\n",
        "plt.imshow(cm)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV7A8Xz-Dmrr"
      },
      "outputs": [],
      "source": [
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "target_layers = [model.layer4[-1]]\n",
        "cam = GradCAM(model=model, target_layers=target_layers)\n",
        "\n",
        "import torchvision\n",
        "inv_norm = transforms.Normalize(\n",
        "    mean=[-m/s for m,s in zip([0.485,0.456,0.406],[0.229,0.224,0.225])],\n",
        "    std=[1/s for s in [0.229,0.224,0.225]]\n",
        ")\n",
        "\n",
        "os.makedirs('cam_samples', exist_ok=True)\n",
        "\n",
        "count = 0\n",
        "for img_path, label in test_ds.samples[:8]:\n",
        "    img = val_tfms(To3Channel()(Image.open(img_path)))\n",
        "    input_tensor = img.unsqueeze(0).to(device)\n",
        "    grayscale_cam = cam(input_tensor=input_tensor)[0]\n",
        "\n",
        "    vis = inv_norm(img).permute(1,2,0).cpu().numpy()\n",
        "    vis = np.clip(vis,0,1)\n",
        "    cam_image = show_cam_on_image(vis, grayscale_cam, use_rgb=True)\n",
        "    out_path = f'cam_samples/{os.path.basename(img_path)}_cam.jpg'\n",
        "    cv2.imwrite(out_path, cv2.cvtColor(cam_image, cv2.COLOR_RGB2BGR))\n",
        "    count += 1\n",
        "print('Saved CAMs to cam_samples/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8BSVvd0E-LZ"
      },
      "outputs": [],
      "source": [
        "import os, json\n",
        "assert os.path.exists('xray_resnet50.pth'), 'Model missing!'\n",
        "assert os.path.exists('labels.json'), 'labels.json missing!'\n",
        "print('Artifacts ready for serving.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kkLEm6n9okkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwSbUmwZJUph"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"best_model.pth\")\n",
        "from google.colab import files\n",
        "files.download(\"best_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsQnBeEWKFn0"
      },
      "outputs": [],
      "source": [
        "# !pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet50(pretrained=False)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)\n",
        "model.load_state_dict(torch.load(\"best_model.pth\", map_location=\"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def predict(image):\n",
        "    img = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img)\n",
        "        probs = torch.softmax(outputs, dim=1)[0].tolist()\n",
        "    return { \"Class 0\": probs[0], \"Class 1\": probs[1] }\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Label(num_top_classes=2),\n",
        "    title=\"Medical X-Ray Classifier\",\n",
        "    description=\"Upload an X-ray image and see diagnosis probabilities\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72185d93"
      },
      "source": [
        "You need to provide your ngrok authtoken to `pyngrok`. You can get this from your ngrok dashboard after signing up for a free account.\n",
        "\n",
        "Add your authtoken to Colab's secrets manager (under the üîë icon in the left panel) with the name `NGROK_AUTH_TOKEN`.\n",
        "\n",
        "Then, add the following code cell to configure `pyngrok`:"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}